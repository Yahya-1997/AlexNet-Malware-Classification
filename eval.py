import numpy as np
import tensorflow as tf
from datagenerator import ImageDataGenerator
Iterator = tf.compat.v1.data.Iterator
batch_size = 1

with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    saver = tf.train.import_meta_graph(r'tmp\finetune_alexnet\checkpoints\model_epoch30.ckpt.meta')
    saver.restore(sess,tf.train.latest_checkpoint(r'tmp\finetune_alexnet\checkpoints'))
    graph = tf.get_default_graph()
    # for op in tf.get_default_graph().get_operations():
       # print(str(op.name))
    images = graph.get_tensor_by_name('Placeholder:0')
    labels = graph.get_tensor_by_name('Placeholder_1:0')
    keep_prob = graph.get_tensor_by_name('Placeholder_2:0')

    score = graph.get_tensor_by_name('fc8/fc8:0')
    # score = [n.name for n in tf.get_default_graph().as_graph_def().node]
    # for name in score:
       # print(name)
    # print(score.shape)
    val_file = os.path.join(os.path.dirname(os.path.abspath(__file__)) , 'val.txt')
    val_data = ImageDataGenerator(val_file,
                                  mode='inference',
                                  batch_size=32,
                                  num_classes=12,
                                  shuffle=False)
                                  
    iterator = Iterator.from_structure(val_data.data.output_types, val_data.data.output_shapes)
    next_batch = iterator.get_next()
    validation_init_op = iterator.make_initializer(val_data.data)
    val_batches_per_epoch = int(np.floor(val_data.data_size / batch_size))
    sess.run(validation_init_op)
    file = open('predictions.txt', 'w')
    for _ in range(12):
        img_batch, label_batch = sess.run(next_batch)
        predicts = sess.run(score, feed_dict={images: img_batch, labels: label_batch, keep_prob: 1.0})
        for i in range(32):
            file.write(str(label_batch[i].argmax()) + " " + str(predicts[i].argmax()) + '\n')
        
    file.close()